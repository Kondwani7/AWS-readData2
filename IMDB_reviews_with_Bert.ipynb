{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IMDB reviews with Bert.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMFWg177VZQ5dWEe3qNRsox",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kondwani7/AWS-readData2/blob/main/IMDB_reviews_with_Bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOxhp5vS6vpu"
      },
      "source": [
        "#Bidirectional Encoded Representations from Transformers BERT, a large step from an LSTM, an array of transformers, mainlu used for Deep learning NLP tasks\n",
        "# by bidrectional, it means it no longer restricted to the left to right (feed forward) structure of previous models and transformers\n",
        "#making it ideal for fine tuning, such as question and answering, not to restricted to specific architechures"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlgqQWqPFz9_",
        "outputId": "c0217394-73df-44df-e63e-2d47e553ca82"
      },
      "source": [
        "# A dependency of the preprocessing for BERT inputs\n",
        "!pip install -q -U tensorflow-text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 4.3 MB 7.7 MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2H27jlS8F5cd",
        "outputId": "b1de5fab-da65-4a09-a5ab-702b8822fe6a"
      },
      "source": [
        "#get the various models\n",
        "!pip install -q tf-models-official"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.6 MB 7.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 54 kB 3.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 43 kB 2.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 679 kB 49.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 636 kB 50.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 211 kB 50.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 99 kB 11.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 352 kB 45.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 48.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 37.1 MB 47 kB/s \n",
            "\u001b[?25h  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJ1LxIIzGAgQ"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "from official.nlp import optimization # create a custom AdamW optimizer\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "tf.get_logger().setLevel('ERROR')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VlaLYQmSGOgM",
        "outputId": "46735efc-8049-4ba6-ef48-dfab72d9d3df"
      },
      "source": [
        "#download the data\n",
        "url = 'https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz'\n",
        "\n",
        "dataset = tf.keras.utils.get_file('aclImdb_v1.tar.gz', url,\n",
        "                                  untar=True, cache_dir='.',\n",
        "                                  cache_subdir='')\n",
        "\n",
        "dataset_dir = os.path.join(os.path.dirname(dataset), 'aclImdb')\n",
        "\n",
        "train_dir = os.path.join(dataset_dir, 'train')\n",
        "\n",
        "# remove unused folders to make it easier to load the data\n",
        "remove_dir = os.path.join(train_dir, 'unsup')\n",
        "shutil.rmtree(remove_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "84131840/84125825 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P41MlKPHHJqN",
        "outputId": "e39bfa35-f382-4325-b5ef-c987c6d160eb"
      },
      "source": [
        "#label the data set, providing a train, validation and test split from 50,000 reviews\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "batch_size = 32\n",
        "seed = 44\n",
        "\n",
        "raw_train_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
        "    'aclImdb/train',\n",
        "    batch_size = batch_size,\n",
        "    validation_split = 0.2,\n",
        "    subset='training',\n",
        "    seed=seed\n",
        ")\n",
        "\n",
        "class_names = raw_train_ds.class_names\n",
        "train_ds = raw_train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "\n",
        "val_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
        "    'aclImdb/train',\n",
        "    batch_size=batch_size,\n",
        "    validation_split=0.2,\n",
        "    subset='validation',\n",
        "    seed=seed)\n",
        "\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "test_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
        "    'aclImdb/test',\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 25000 files belonging to 2 classes.\n",
            "Using 20000 files for training.\n",
            "Found 25000 files belonging to 2 classes.\n",
            "Using 5000 files for validation.\n",
            "Found 25000 files belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FngchzbTJFFh",
        "outputId": "56346782-4559-4521-aeb1-f2e8f3fb63c0"
      },
      "source": [
        "#look at individual 3 types of reviews\n",
        "for text_batch, label_batch in train_ds.take(3):\n",
        "  for i in range(3):\n",
        "    print(f'Review: {text_batch.numpy()[i]}')\n",
        "    label = label_batch.numpy()[i]\n",
        "    print(f'Label: {label} ({class_names[label]})')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Review: b\"I wish I had my rental money back from this piece of trash so I could donate it to the Home for Aged Actors. Total rubbish!! Five people watched this movie at the same time and there wasn't one single laugh to be heard, lots of yawning though. Paltrow's a beautiful woman and she was the best thing to look at in the entire so-called comedic movie..\"\n",
            "Label: 0 (neg)\n",
            "Review: b\"I just finished watching the 139 min version (widescreen) with some friends and we were blown away. I won't bother repeating what others have said. What the filmmakers do with the concept is unexpected and fun. The huge battle is exhausting. Afterwards we were stunned to find there was still nearly 30 minutes left to go but that didn't keep us from being completely involved and entertained.<br /><br />There is one thing that nearly ruined it and that was the horrific music/songs. Blues, Country/Folk and Rock Ballads do not belong here and every time they are used we all broke out in laughter. It's hideous. You have been warned but the story and storytelling keeps you grounded.<br /><br />There are several outstanding moments that make you appreciate the talent behind the camera. There are many uses of silence as well as slow-motion photography that work beautifully. I really wish I could erase the music but alas.<br /><br />Seek this out. It's fun, it's different and it takes you to places you wouldn't expect and that's very refreshing.\"\n",
            "Label: 1 (pos)\n",
            "Review: b'This film is very interesting. I have seen it twice and it seems Glover hit the nail on the head with what he claims to he wants to accomplish. I for one can relate to the outrage that the filmmaker clearly expresses against the current thoughtless corporate drivel that is an onslaught in our every media center, and the things that we as a culture are supposed to not \"think\" about due to corporate media control. The outrage that Glover expresses through the \"outrageous\" elements in the films is both clear in its visceral aggressiveness and beautiful in its poetic potency. I am glad I saw this film and it is even clearer that Glover is up to something interesting with part two of what will be a trilogy. It is fine! EVERYTHING IS FINE. See that also. People that dismiss this film as \"thoughtless\" or \"pretentious\" are really missing the boat. This is an intelligent films. If you can see it with his live show he performs before with his books, that is also very wroth while. The way you get in to his mindset is really something. You will have an experience!'\n",
            "Label: 1 (pos)\n",
            "Review: b\"I just watched The Convent for the second time. I had enjoyed it previously and figured it would make for a good drunken Friday night film, some gore, some style, bit of humour and suchlike. I was saddened to find that I could no longer appreciate it much. It seemed like someone had set out to revisit cheeseball epics like Night of the Demons for a modern audience but lost the things that made the original worthwhile. For the record I'm not even a huge fan of Night of the Demons, but there were some things I really dug about it. The Convent does the cheese but the not the goodness so much. Apart from the main girl (likeable performance from Joanna Canton), the goth girl and a sweet cameo from Adrienne Barbeau pretty much all the characters were excruciatingly unlikeable, festering at the absolute lowest levels of moronic, offensive jockhood. The film is then gravely hampered by the complete lack of gratuitous nudity which means that, given the awful dialogue, it is difficult to watch the characters and harder to appreciate the good points of the film. The evil nuns are original in design and get lots of good scenes, though not scary their certainly kinda cool, and the film also fields a fair amount of neat gore. Towards the end, when Adrienne Barbeau is on the scene the film becomes quite entertaining cause all the obnoxious people are dead and its an evil nun bashing frenzy. The stylised direction also occasionally yields good results, although sometimes the camera just moves too fast. All in all, this was a film where for me the shining good points just can't make up for the things I hated. Those more fond of this kind of film may well enjoy it a lot more, but for me it wasn't a good time.\"\n",
            "Label: 0 (neg)\n",
            "Review: b'I was unsure whether or not Andy Sidaris could repeat his success with the cinematic hit \"Malibu Express.\" With his film Fit to Kill he has proved that Sidaris is a serious filmmaker and not just a one-shot director. The plot written by Sidaris, which was ungratefully passed up by the Academy, is a complex screenplay involving many unseen twists and turns. The main characters composed work for a sexually based radio station known as KSXY. Cleverly, KSXY is actually their secret headquarters. In \"Fit to Kill\" they confront their long-time nemesis Kane, who is trying to steal one of Russia\\'s most prized diamonds. A well-written screenplay is not all, excellent acting by the cast helps to ensure this film as a cult classic. Panned by the critics and the box office, this film will be appreciated in years to come. It is now suffering the same fate as Clockwork Orange and Taxi Driver did, but in the future will undoubtly become recognized. I am disappointed no critic circles have recognized Andy Sidaris\\'s trademark filmmaking. The costumes, the special effects, all help to compliment this already beautiful piece of filmmaking. It may do you best to ignore the dismal 3 rating on this film and go out and rent it for yourself. My personal rating is 10/10. The drama is as thick as the blockbuster Runaway Bride, and the action better or equal to the cinematic masterpiece Last Action Hero. Andy, keep up the good work.'\n",
            "Label: 0 (neg)\n",
            "Review: b\"Sure, if you ask any mom who's the most beautiful baby in the world, she'd tell you her son is the most amazing kid in the whole world. She's right, at least in her own world.<br /><br />The producers of the movie were biggie's mother and his good friend Puffy. Oh, well, do I need to say more? I'll break it down for those who doesn't want to do a simple deduction.<br /><br />The whole movie was fake. You may just put a few biggie's MTV video together and call it a movie.<br /><br />The beautiful Angela Bassett played Biggie's mother. The real one in life looks like a dog.<br /><br />I just wonder why he called himself biggie small. Big body Small dick? Big mouth Small sound? Big fat Small eyes? Disclaimer: I'm a person of color. So keep your racist remark to yourself.\"\n",
            "Label: 0 (neg)\n",
            "Review: b\"Pakeezah has a very interesting history (which is well documented in the 'Trivia' section) about how it came to be. It seems as if destiny conspired to test Kamal Amrohi (the director) while at the same time secretly desiring to see him complete his masterpiece.<br /><br />Pakeezah rides on metaphors, poetry and visual elocution. As a result the intensity with which emotions come out achieve a dimension which may not be very real but are very effective and leave an impact on the viewer.<br /><br />Meena Kumari lives the tragedy of Nargis and Sahib Jaan like her own. The other stars of the film, besides her, are Ghulam Mohammed (the music director), Lata Mangeshkar, Naushad (background score) and Joseph Wirsching (the d.o.p). Their music and cinematography leaves you spell bound.<br /><br />Pakeezah is a classic in world cinema. It reveals new layers to you every time you watch it again. Kamal Amrohi is one of the rare poets of cinema and he left us all a gift.\"\n",
            "Label: 1 (pos)\n",
            "Review: b'It\\'s only 2 episodes into a 5 part drama, but I can already state that this is one of the best things I\\'ve ever seen. That\\'s on TV, silver screen or even in real life.<br /><br />As a writer, it\\'s so good it\\'s almost demoralising! As a viewer it\\'s so entertaining that I\\'m annoyed the episodes are over a fortnight instead of Monday to Friday. It\\'s clear that all these negatives are actually positives.<br /><br />I\\'m a modern guy who previously turned over from TV dramas. In comparison to movies, TV dramas always seemed to be dated, quite tame, and well, generally boring! \"Five Days\" has really brought TV drama into the 21st Century, so for me at least, it\\'s mind changing. Go watch it.'\n",
            "Label: 1 (pos)\n",
            "Review: b\"Like so many media experiments, this amateurish effort contains seeds of a very interesting social commentary. In the 5+ years since it was released, the premise has been made less outrageous by real world events in software development, and I found it less boring than the previous commentator for that reason, I imagine... The director clearly is a fan of Hitchcock, and it's too bad that the film was not better executed, but in fact, it is nearly a parody of pulp fiction, including the soundtrack screeching at us when we are supposed to pay attention. One can almost see the exclamation points and capital letters on a yellowing page.<br /><br />I have to admit I found it rather entertaining for all these reasons and more. Sometimes the slick has less to offer us, and I would recommend it to anyone interested in deconstructing it for education purposes. Oh yes--and even though the seams showed and it creaked a lot, my heart rate went up, and I was reluctant to get up and take a break.\"\n",
            "Label: 0 (neg)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xv30YfjjKFs2",
        "outputId": "49413a17-28b0-470a-a5a7-b91713079250"
      },
      "source": [
        "#@title Choose a BERT model to fine-tune\n",
        "\n",
        "bert_model_name = 'small_bert/bert_en_uncased_L-4_H-512_A-8'  #@param [\"bert_en_uncased_L-12_H-768_A-12\", \"bert_en_cased_L-12_H-768_A-12\", \"bert_multi_cased_L-12_H-768_A-12\", \"small_bert/bert_en_uncased_L-2_H-128_A-2\", \"small_bert/bert_en_uncased_L-2_H-256_A-4\", \"small_bert/bert_en_uncased_L-2_H-512_A-8\", \"small_bert/bert_en_uncased_L-2_H-768_A-12\", \"small_bert/bert_en_uncased_L-4_H-128_A-2\", \"small_bert/bert_en_uncased_L-4_H-256_A-4\", \"small_bert/bert_en_uncased_L-4_H-512_A-8\", \"small_bert/bert_en_uncased_L-4_H-768_A-12\", \"small_bert/bert_en_uncased_L-6_H-128_A-2\", \"small_bert/bert_en_uncased_L-6_H-256_A-4\", \"small_bert/bert_en_uncased_L-6_H-512_A-8\", \"small_bert/bert_en_uncased_L-6_H-768_A-12\", \"small_bert/bert_en_uncased_L-8_H-128_A-2\", \"small_bert/bert_en_uncased_L-8_H-256_A-4\", \"small_bert/bert_en_uncased_L-8_H-512_A-8\", \"small_bert/bert_en_uncased_L-8_H-768_A-12\", \"small_bert/bert_en_uncased_L-10_H-128_A-2\", \"small_bert/bert_en_uncased_L-10_H-256_A-4\", \"small_bert/bert_en_uncased_L-10_H-512_A-8\", \"small_bert/bert_en_uncased_L-10_H-768_A-12\", \"small_bert/bert_en_uncased_L-12_H-128_A-2\", \"small_bert/bert_en_uncased_L-12_H-256_A-4\", \"small_bert/bert_en_uncased_L-12_H-512_A-8\", \"small_bert/bert_en_uncased_L-12_H-768_A-12\", \"albert_en_base\", \"electra_small\", \"electra_base\", \"experts_pubmed\", \"experts_wiki_books\", \"talking-heads_base\"]\n",
        "\n",
        "map_name_to_handle = {\n",
        "    'bert_en_uncased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3',\n",
        "    'bert_en_cased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/3',\n",
        "    'bert_multi_cased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-768_A-12/1',\n",
        "    'albert_en_base':\n",
        "        'https://tfhub.dev/tensorflow/albert_en_base/2',\n",
        "    'electra_small':\n",
        "        'https://tfhub.dev/google/electra_small/2',\n",
        "    'electra_base':\n",
        "        'https://tfhub.dev/google/electra_base/2',\n",
        "    'experts_pubmed':\n",
        "        'https://tfhub.dev/google/experts/bert/pubmed/2',\n",
        "    'experts_wiki_books':\n",
        "        'https://tfhub.dev/google/experts/bert/wiki_books/2',\n",
        "    'talking-heads_base':\n",
        "        'https://tfhub.dev/tensorflow/talkheads_ggelu_bert_en_base/1',\n",
        "}\n",
        "\n",
        "map_model_to_preprocess = {\n",
        "    'bert_en_uncased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'bert_en_cased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_cased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'bert_multi_cased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3',\n",
        "    'albert_en_base':\n",
        "        'https://tfhub.dev/tensorflow/albert_en_preprocess/3',\n",
        "    'electra_small':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'electra_base':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'experts_pubmed':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'experts_wiki_books':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'talking-heads_base':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "}\n",
        "\n",
        "tfhub_handle_encoder = map_name_to_handle[bert_model_name]\n",
        "tfhub_handle_preprocess = map_model_to_preprocess[bert_model_name]\n",
        "\n",
        "print(f'BERT model selected           : {tfhub_handle_encoder}')\n",
        "print(f'Preprocess model auto-selected: {tfhub_handle_preprocess}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BERT model selected           : https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
            "Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEKZyTbZNBlJ"
      },
      "source": [
        "#select the model ideal for preprocessing your reviews, into numeric tokens\n",
        "bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BrQGqWQANlSn",
        "outputId": "886104b2-82e0-4cb8-f75a-bc98d044a529"
      },
      "source": [
        "#testing same text to see its preprocessing output\n",
        "test_text = ['this is movie is lit one the best action movies of all time']\n",
        "text_preprocessed = bert_preprocess_model(text_test)\n",
        "\n",
        "print(f'Keys       : {list(text_preprocessed.keys())}')\n",
        "print(f'Shape      : {text_preprocessed[\"input_word_ids\"].shape}')\n",
        "print(f'Word Ids   : {text_preprocessed[\"input_word_ids\"][0, :12]}')\n",
        "print(f'Input Mask : {text_preprocessed[\"input_mask\"][0, :12]}')\n",
        "print(f'Type Ids   : {text_preprocessed[\"input_type_ids\"][0, :12]}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Keys       : ['input_word_ids', 'input_type_ids', 'input_mask']\n",
            "Shape      : (1, 128)\n",
            "Word Ids   : [ 101 2023 2003 2107 2019 6429 3185  999  102    0    0    0]\n",
            "Input Mask : [1 1 1 1 1 1 1 1 1 0 0 0]\n",
            "Type Ids   : [0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVfVpoM8OI8A"
      },
      "source": [
        "bert_model = hub.KerasLayer(tfhub_handle_encoder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTiC_Py9PCMy",
        "outputId": "4cca1fc7-0788-47b9-c623-61ef41e46842"
      },
      "source": [
        "bert_results = bert_model(text_preprocessed)\n",
        "#testing the preprocessing results\n",
        "#pooled output, basically represents the total input sequence. the embedding layer\n",
        "#sequence output, represents each input sequence\n",
        "#encoder_outputs gradual activations in different transformer blocks\n",
        "print(f'Loaded BERT: {tfhub_handle_encoder}')\n",
        "print(f'Pooled Outputs Shape:{bert_results[\"pooled_output\"].shape}')\n",
        "print(f'Pooled Outputs Values:{bert_results[\"pooled_output\"][0, :12]}')\n",
        "print(f'Sequence Outputs Shape:{bert_results[\"sequence_output\"].shape}')\n",
        "print(f'Sequence Outputs Values:{bert_results[\"sequence_output\"][0, :12]}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded BERT: https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
            "Pooled Outputs Shape:(1, 512)\n",
            "Pooled Outputs Values:[ 0.7626293   0.9928098  -0.18611859  0.36673865  0.15233742  0.6550452\n",
            "  0.9681154  -0.94862705  0.00216148 -0.9877732   0.0684269  -0.9763061 ]\n",
            "Sequence Outputs Shape:(1, 128, 512)\n",
            "Sequence Outputs Values:[[-0.28946307  0.34321287  0.33231482 ...  0.21300784  0.7102064\n",
            "  -0.05771124]\n",
            " [-0.28742093  0.3198104  -0.2301862  ...  0.58455014 -0.21329764\n",
            "   0.7269209 ]\n",
            " [-0.6615701   0.6887682  -0.8743294  ...  0.10877228 -0.26173192\n",
            "   0.4785537 ]\n",
            " ...\n",
            " [-0.22561091 -0.28925657 -0.07064448 ...  0.47566032  0.8327713\n",
            "   0.40025362]\n",
            " [-0.298242   -0.27473173 -0.05450522 ...  0.48849788  1.0955355\n",
            "   0.18163413]\n",
            " [-0.44378197  0.00930735  0.07223716 ...  0.172901    1.1833245\n",
            "   0.07898018]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOhX2atEP1Tx"
      },
      "source": [
        "#build a model for classification\n",
        "\n",
        "def build_classifier_model():\n",
        "  text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "  preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n",
        "  encoder_inputs = preprocessing_layer(text_input)\n",
        "  encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
        "  outputs = encoder(encoder_inputs)\n",
        "  net = outputs['pooled_output']\n",
        "  net = tf.keras.layers.Dropout(0.1)(net)\n",
        "  net = tf.keras.layers.Dense(1, activation=None, name='classifier')(net)\n",
        "  return tf.keras.Model(text_input, net)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBb_xTmfRFTX",
        "outputId": "6dadc430-3e2f-494b-cc6a-ebb413de7418"
      },
      "source": [
        "#test see if the classifier gives a desired output\n",
        "model = build_classifier_model()\n",
        "bert_raw_result = model(tf.constant(test_text))\n",
        "print(tf.sigmoid(bert_raw_result))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([[0.4778468]], shape=(1, 1), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "hoaXWvAOReA3",
        "outputId": "8e1e34d5-c172-4744-a7b7-42e215df75a9"
      },
      "source": [
        "#view the model's architechure\n",
        "tf.keras.utils.plot_model(model)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZm7jedPSzjq"
      },
      "source": [
        "#predefining model compling parameters\n",
        "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "metrics = tf.metrics.BinaryAccuracy()\n",
        "#predefining metrics for optimizing the model\n",
        "epochs = 5\n",
        "steps_per_epoch = tf.data.experimental.cardinality(train_ds).numpy()\n",
        "num_train_steps = steps_per_epoch * epochs\n",
        "num_warmup_steps = int(0.1 * num_train_steps)\n",
        "#inital learning rate\n",
        "init_lr = 3e-5\n",
        "\n",
        "#optimizer\n",
        "optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
        "                                          num_train_steps=num_train_steps,\n",
        "                                          num_warmup_steps=num_warmup_steps,\n",
        "                                          optimizer_type='adamw')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNZtHzWjT5Ap"
      },
      "source": [
        "model.compile(optimizer=optimizer,\n",
        "                         loss=loss,\n",
        "                         metrics=metrics)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90wJ4-IwU7PG",
        "outputId": "845c6ad3-3be9-4222-c92c-4c4f62f26cab"
      },
      "source": [
        "#fitting and running the model\n",
        "print(f'Training my model with {tfhub_handle_encoder}')\n",
        "history = model.fit(\n",
        "    x=train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=epochs\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training my model with https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
            "Epoch 1/5\n",
            "625/625 [==============================] - 3602s 6s/step - loss: 0.4762 - binary_accuracy: 0.7496 - val_loss: 0.3504 - val_binary_accuracy: 0.8422\n",
            "Epoch 2/5\n",
            "625/625 [==============================] - 3590s 6s/step - loss: 0.3317 - binary_accuracy: 0.8493 - val_loss: 0.3586 - val_binary_accuracy: 0.8582\n",
            "Epoch 3/5\n",
            "625/625 [==============================] - 3608s 6s/step - loss: 0.2546 - binary_accuracy: 0.8951 - val_loss: 0.3839 - val_binary_accuracy: 0.8602\n",
            "Epoch 4/5\n",
            "625/625 [==============================] - 3618s 6s/step - loss: 0.1963 - binary_accuracy: 0.9218 - val_loss: 0.4238 - val_binary_accuracy: 0.8608\n",
            "Epoch 5/5\n",
            "625/625 [==============================] - 3617s 6s/step - loss: 0.1556 - binary_accuracy: 0.9416 - val_loss: 0.4345 - val_binary_accuracy: 0.8614\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atVZ3EW5jRY7"
      },
      "source": [
        "#evaluate accuracy with the test data\n",
        "loss, accuracy = model.evaluate(test_ds)\n",
        "print(f'Loss: {loss}')\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print(f'Loss: {loss}')\n",
        "print(f'Accuracy: {accuracy}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNvYQ4BPyioZ"
      },
      "source": [
        "#plot the change in accuracy overtime for both train and test data\n",
        "history_dict = history.history\n",
        "print(history_dict.key())\n",
        "\n",
        "acc = history_dict['binary_accuracy']\n",
        "val_acc = history_dict['val_binary_accuracy']\n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "fig = plt.figure(figsize=(10, 6))\n",
        "fig.tight_layout()\n",
        "\n",
        "plt.subplot(2,1,1)\n",
        "plt.plot(epochs, loss, 'r', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.ylable\n",
        "\n",
        "acc = history_dict['binary_accuracy']\n",
        "val_acc = history_dict['val_binary_accuracy']\n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "fig = plt.figure(figsize=(10, 6))\n",
        "fig.tight_layout()\n",
        "\n",
        "plt.subplot(2, 1, 1)\n",
        "# \"bo\" is for \"blue dot\"\n",
        "plt.plot(epochs, loss, 'r', label='Training loss')\n",
        "# b is for \"solid blue line\"\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(epochs, acc, 'r', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='lower right')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEs0n6e7z6rU"
      },
      "source": [
        "#save your model for other uses\n",
        "dataset_name = 'imdb'\n",
        "review_classifier = './{}_bert'.format(dataset_name.replace('/','_'))\n",
        "model.save(review_classifier, include_optimizer=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-shEGMfD0PDY"
      },
      "source": [
        "#reload your model\n",
        "reloaded_model = tf.saved_model.load(review_classifier)\n",
        "reloaded_model = tf.saved_model.load(review_classifier)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nacibgTJ0lo4"
      },
      "source": [
        "#test your sample on any random results\n",
        "def print_gen_examples(inputs, results):\n",
        "  result_for_printing = \\\n",
        "  [f'input: {inputs[i]:<30}: score: {results[i][0]:.6f}'\n",
        "  for in range(len(inputs))]\n",
        "\n",
        "  print(*result_for_printing, sep='\\n')\n",
        "  print()\n",
        "\n",
        "examples = [\n",
        "  'this is such an amazing movie!',  \n",
        "  'The movie was great!',\n",
        "  'The movie was meh.',\n",
        "  'The movie was okish.',\n",
        "  'The movie was terrible...'\n",
        "]\n",
        "\n",
        "reloaded_results = tf.sigmoid(reloaded_model(tf.constant(examples)))\n",
        "orginal_results = tf.sigmoid(model(tf.constant(examples)))\n",
        "#performance with the saved model\n",
        "print('Results from the saved model: ')\n",
        "print_gen_examples(examples, reloaded_results)\n",
        "#performance with the model from memory\n",
        "print('Results from the model cached')\n",
        "print_gen_examples(examples, orginial_results)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mLSrlcc2MPA"
      },
      "source": [
        "#TFX serving, practicing how to experiment with models for production\n",
        "serving_results = reloaded_model \\\n",
        "            .signatures['serving_default'](tf.constant(examples))\n",
        "\n",
        "serving_results = tf.sigmoid(serving_results['classifier'])\n",
        "\n",
        "print_gen_examples(examples, serving_results)\n",
        "\n",
        "serving_results = reloaded_model \\\n",
        "            .signatures['serving_default'](tf.constant(examples))\n",
        "\n",
        "serving_results = tf.sigmoid(serving_results['classifier'])\n",
        "\n",
        "print_my_examples(examples, serving_results)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}